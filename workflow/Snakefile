import re
import warnings
from os import getcwd, makedirs, walk
from os.path import abspath, basename, exists, join
from tempfile import gettempdir
from shutil import rmtree
from urllib.parse import urlparse

import numpy as np
import pandas as pd

# https://github.com/snakemake/snakemake/issues/2957
warnings.filterwarnings("ignore", category=RuntimeWarning, module="snakemake.dag")

CONFIG_DIR = "config"
DATA_DIR = "data"
LOG_DIR = "logs"
RESOURCES_DIR = "resources"
RESULTS_DIR = "results"
RULES_DIR = "rules"


configfile: join(CONFIG_DIR, "config.yaml")


STUDY_NAME = config["gdc"]["study_name"]

EXPAND_PARAMS = {}

PUBLIC_WRAPPERS_VERSION = config["wrappers"]["public"]["version"]
PERSONAL_WRAPPERS_BASE_URL = config["wrappers"]["personal"]["base_url"]
LOCAL_WRAPPERS_BASE_URL = config["wrappers"]["local"]["base_url"]

HOST_REF_NAME = config["resources"]["ref"]["name"]
HOST_REF_FASTA_URL = config["resources"]["ref"]["fasta_url"]

GDC_DATA_DIR = join(config["gdc"]["data"]["dir"], config["gdc"]["data"]["sub_dir"])
GDC_BAM_META_FILE = join(GDC_DATA_DIR, f"{STUDY_NAME}_file_meta.tsv")
GDC_READGRP_META_FILE = join(GDC_DATA_DIR, f"{STUDY_NAME}_readgrp_meta.tsv")

KRAKEN2_DB_LIBS = config["resources"]["db"]["libs"]["kraken2"]["names"]
KRAKENUNIQ_DB_LIBS = config["resources"]["db"]["libs"]["krakenuniq"]["names"]

BRACKEN_DB_READ_LENGTHS = config["resources"]["db"]["bracken"]["readlens"]

KRAKEN_DB_BASEDIR = config["resources"]["db"]["base_dir"]
KRAKEN_DB_NAME = config["resources"]["db"]["name"]

EUPATHDB_BASE_URL = config["resources"]["db"]["libs"]["custom"]["eupathdb"]["base_url"]
EUPATHDB_FASTA_TGZ_FILENAME = config["resources"]["db"]["libs"]["custom"]["eupathdb"][
    "fa_tgz_filename"
]
EUPATHDB_SEQID2TAXID_MAP_FILENAME = config["resources"]["db"]["libs"]["custom"][
    "eupathdb"
]["idmap_filename"]

KRAKEN2_K2_SCRIPT_PATH = abspath(join(config["kraken2"]["script_dir"], "k2"))
KRAKEN2_TSEARCH_UNCLASSIF = config["kraken2"]["tsearch_unclassif"]
KRAKEN2_DB_TYPES = ["nucl", "prot"] if KRAKEN2_TSEARCH_UNCLASSIF else ["nucl"]

HOST_FILTER_MODE = config["host_filter"]["mode"]
KRAKEN_MODE = config["read_classif"]["mode"]

BRACKEN_BUILD_SCRIPT_PATH = abspath(
    join(config["bracken"]["script_dir"], "bracken-build")
)

EXPAND_PARAMS["k2dtype"] = KRAKEN2_DB_TYPES
EXPAND_PARAMS["k2nlib"] = KRAKEN2_DB_LIBS
EXPAND_PARAMS["k2plib"] = [
    l
    for l in KRAKEN2_DB_LIBS
    if l not in config["resources"]["db"]["libs"]["kraken2"]["nucl_only"]
]
EXPAND_PARAMS["kulib"] = KRAKENUNIQ_DB_LIBS
EXPAND_PARAMS["readlen"] = BRACKEN_DB_READ_LENGTHS

REF_FASTA_FILE_GZ_NAME = basename(urlparse(HOST_REF_FASTA_URL).path)
REF_FASTA_FILE_NAME = REF_FASTA_FILE_GZ_NAME.removesuffix(".gz").removesuffix(".GZ")
HOST_REF_FASTA_FILE = join(RESOURCES_DIR, "ref", REF_FASTA_FILE_NAME)
HOST_REF_FASTA_LOG = join(LOG_DIR, "ref", f"download_{REF_FASTA_FILE_NAME}.log")

GDC_DATA_LOG_DIR = join(LOG_DIR, "gdc", "data", config["gdc"]["data"]["sub_dir"])
makedirs(GDC_DATA_LOG_DIR, mode=0o755, exist_ok=True)
GDC_DATA_LOG = join(GDC_DATA_LOG_DIR, "gdc_metadata.log")
with open(GDC_DATA_LOG, "wt") as log_fh:
    if not exists(GDC_BAM_META_FILE) or not exists(GDC_READGRP_META_FILE):
        log_fh.write("Getting GDC metadata...\n")
        makedirs(GDC_DATA_DIR, mode=0o755, exist_ok=True)
    else:
        log_fh.write("Using existing GDC metadata\n")
if not exists(GDC_BAM_META_FILE) or not exists(GDC_READGRP_META_FILE):
    shell(f"Rscript ./workflow/scripts/gdc_metadata.R >> {GDC_DATA_LOG} 2>&1")

GDC_BAM_META_DF = pd.read_csv(GDC_BAM_META_FILE, sep="\t").set_index(
    "file_id", drop=False, verify_integrity=True
)
GDC_READGRP_META_DF = pd.read_csv(
    GDC_READGRP_META_FILE, sep="\t", dtype={"is_paired_end": bool, "read_length": int}
).set_index("read_group_id", drop=False, verify_integrity=True)

GDC_TOKEN = os.getenv("GDC_TOKEN")
if GDC_TOKEN is None:
    GDC_TOKEN_FILE = os.getenv("GDC_TOKEN_FILE", "~/.gdc_token")
    if GDC_TOKEN_FILE is not None and exists(GDC_TOKEN_FILE):
        GDC_TOKEN_FILE = GDC_TOKEN_FILE.strip()
        with open(GDC_TOKEN_FILE, "rt") as token_fh:
            GDC_TOKEN = token_fh.readline().strip()
assert (
    GDC_TOKEN is not None
), "GDC auth token not found in GDC_TOKEN, GDC_TOKEN_FILE, or ~/.gdc_token"

EXPAND_PARAMS["bam_id"] = GDC_BAM_META_DF["file_id"].tolist()

GDC_RESULTS_DIR = join(RESULTS_DIR, "gdc")
GDC_LOG_DIR = join(LOG_DIR, "gdc")
GDC_UNMAPPED_BAM_FILE = join(GDC_RESULTS_DIR, "bam", "{bam_id}_unmapped.bam")
GDC_UNMAPPED_BAM_LOG = join(GDC_LOG_DIR, "bam", "{bam_id}_unmapped_bam.log")
GDC_FASTQ_RESULTS_DIR = join(GDC_RESULTS_DIR, "fastq")
GDC_UNMAPPED_FASTQ_DIR = join(GDC_FASTQ_RESULTS_DIR, "{bam_id}")
GDC_UNMAPPED_FASTQ_R1_FILE = join(GDC_UNMAPPED_FASTQ_DIR, "{rg_id}_unmapped_1.fq.gz")
GDC_UNMAPPED_FASTQ_R2_FILE = join(GDC_UNMAPPED_FASTQ_DIR, "{rg_id}_unmapped_2.fq.gz")
GDC_UNMAPPED_FASTQ_SE_FILE = join(GDC_UNMAPPED_FASTQ_DIR, "{rg_id}_unmapped_s.fq.gz")
GDC_UNMAPPED_FASTQ_LOG = join(GDC_LOG_DIR, "fastq", "{bam_id}_unmapped_fastq.log")

HOST_GENOME_INDEX_DIR = join(RESOURCES_DIR, HOST_FILTER_MODE, "index")
HOST_GENOME_LOG_DIR = join(LOG_DIR, HOST_FILTER_MODE, "index")
HOST_GENOME_INDEX_PREFIX = join(HOST_GENOME_INDEX_DIR, HOST_REF_NAME)
HOST_GENOME_INDEX_LOG = join(HOST_GENOME_LOG_DIR, f"{HOST_REF_NAME}.log")

HOST_FILTER_RESULTS_DIR = join(RESULTS_DIR, HOST_FILTER_MODE, "align")
HOST_FILTER_LOG_DIR = join(LOG_DIR, HOST_FILTER_MODE, "align")
HOST_FILTER_FILE_RESULTS_DIR = join(HOST_FILTER_RESULTS_DIR, "{bam_id}")
HOST_FILTER_FILE_LOG_DIR = join(HOST_FILTER_LOG_DIR, "{bam_id}")
HOST_BAM_PE_FILE = join(HOST_FILTER_FILE_RESULTS_DIR, "{rg_id}.bam")
HOST_BAM_SE_FILE = join(HOST_FILTER_FILE_RESULTS_DIR, "{rg_id}.bam")
HOST_FILTERED_FASTQ_R1_FILE = join(
    HOST_FILTER_FILE_RESULTS_DIR, "{rg_id}_filtered_1.fq.gz"
)
HOST_FILTERED_FASTQ_R2_FILE = join(
    HOST_FILTER_FILE_RESULTS_DIR, "{rg_id}_filtered_2.fq.gz"
)
HOST_FILTERED_FASTQ_SE_FILE = join(
    HOST_FILTER_FILE_RESULTS_DIR, "{rg_id}_filtered_s.fq.gz"
)
HOST_FILTERED_FASTQ_LOG = join(HOST_FILTER_FILE_LOG_DIR, "{rg_id}_filtered_fastq.log")

KRAKEN2_RESOURCES_DIR = join(RESOURCES_DIR, "kraken2")
KRAKEN2_RESULTS_DIR = join(RESULTS_DIR, "kraken2")
KRAKEN2_LOG_DIR = join(LOG_DIR, "kraken2")

KRAKEN2_DB_DIR = join(KRAKEN_DB_BASEDIR, KRAKEN_DB_NAME, "{k2dtype}")
KRAKEN2_NUCL_DB_DIR = join(KRAKEN_DB_BASEDIR, KRAKEN_DB_NAME, "nucl")
KRAKEN2_PROT_DB_DIR = join(KRAKEN_DB_BASEDIR, KRAKEN_DB_NAME, "prot")

KRAKEN2_DB_LOG_DIR = join(KRAKEN2_LOG_DIR, "db", KRAKEN_DB_NAME, "{k2dtype}")
KRAKEN2_NUCL_DB_LOG_DIR = join(KRAKEN2_LOG_DIR, "db", KRAKEN_DB_NAME, "nucl")
KRAKEN2_PROT_DB_LOG_DIR = join(KRAKEN2_LOG_DIR, "db", KRAKEN_DB_NAME, "prot")

KRAKEN2_DB_TAX_DIR = join(KRAKEN2_DB_DIR, "taxonomy")
KRAKEN2_NUCL_DB_TAX_DIR = join(KRAKEN2_NUCL_DB_DIR, "taxonomy")
KRAKEN2_PROT_DB_TAX_DIR = join(KRAKEN2_PROT_DB_DIR, "taxonomy")

KRAKEN2_DB_TAX_LOG = join(KRAKEN2_DB_LOG_DIR, "download_taxonomy.log")
KRAKEN2_DB_TAX_DONE_FILE = join(KRAKEN2_DB_TAX_DIR, "download_taxonomy.done")
KRAKEN2_NUCL_DB_TAX_DONE_FILE = join(KRAKEN2_NUCL_DB_TAX_DIR, "download_taxonomy.done")
KRAKEN2_PROT_DB_TAX_DONE_FILE = join(KRAKEN2_PROT_DB_TAX_DIR, "download_taxonomy.done")

KRAKEN2_NUCL_DB_LIB_DIR = join(KRAKEN2_NUCL_DB_DIR, "library", "{k2nlib}")
KRAKEN2_NUCL_DB_LIB_LOG = join(KRAKEN2_NUCL_DB_LOG_DIR, "{k2nlib}_library.log")
KRAKEN2_NUCL_DB_LIB_DONE_FILE = join(KRAKEN2_NUCL_DB_LIB_DIR, "{k2nlib}_library.done")
KRAKEN2_PROT_DB_LIB_DIR = join(KRAKEN2_PROT_DB_DIR, "library", "{k2plib}")
KRAKEN2_PROT_DB_LIB_LOG = join(KRAKEN2_PROT_DB_LOG_DIR, "{k2plib}_library.log")
KRAKEN2_PROT_DB_LIB_DONE_FILE = join(KRAKEN2_PROT_DB_LIB_DIR, "{k2plib}_library.done")

KRAKEN2_DB_LOG = join(KRAKEN2_DB_LOG_DIR, "kraken2_db.log")
KRAKEN2_DB_DONE_FILE = join(KRAKEN2_DB_DIR, "kraken2_db.done")
KRAKEN2_NUCL_DB_DONE_FILE = join(KRAKEN2_NUCL_DB_DIR, "kraken2_db.done")
KRAKEN2_PROT_DB_DONE_FILE = join(KRAKEN2_PROT_DB_DIR, "kraken2_db.done")

KRAKEN2_NUCL_CLASSIFY_RESULTS_DIR = join(
    KRAKEN2_RESULTS_DIR, "classify", KRAKEN_DB_NAME, "nucl"
)
KRAKEN2_NUCL_CLASSIFY_LOG_DIR = join(
    KRAKEN2_LOG_DIR, "classify", KRAKEN_DB_NAME, "nucl"
)
KRAKEN2_PROT_CLASSIFY_RESULTS_DIR = join(
    KRAKEN2_RESULTS_DIR, "classify", KRAKEN_DB_NAME, "prot"
)
KRAKEN2_PROT_CLASSIFY_LOG_DIR = join(
    KRAKEN2_LOG_DIR, "classify", KRAKEN_DB_NAME, "prot"
)

KRAKEN2_NUCL_CLASSIFY_FILE_RESULTS_DIR = join(
    KRAKEN2_NUCL_CLASSIFY_RESULTS_DIR, "{bam_id}"
)
KRAKEN2_NUCL_CLASSIFY_FILE_LOG_DIR = join(KRAKEN2_NUCL_CLASSIFY_LOG_DIR, "{bam_id}")
KRAKEN2_PROT_CLASSIFY_FILE_RESULTS_DIR = join(
    KRAKEN2_PROT_CLASSIFY_RESULTS_DIR, "{bam_id}"
)
KRAKEN2_PROT_CLASSIFY_FILE_LOG_DIR = join(KRAKEN2_PROT_CLASSIFY_LOG_DIR, "{bam_id}")

KRAKEN2_NUCL_CLASSIF_FASTQ_R1_FILE = join(
    KRAKEN2_NUCL_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_classif_1.fq"
)
KRAKEN2_NUCL_CLASSIF_FASTQ_R2_FILE = join(
    KRAKEN2_NUCL_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_classif_2.fq"
)
KRAKEN2_NUCL_CLASSIF_FASTQ_SE_FILE = join(
    KRAKEN2_NUCL_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_classif_s.fq"
)
KRAKEN2_NUCL_UNCLASSIF_FASTQ_R1_FILE = join(
    KRAKEN2_NUCL_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_unclassif_1.fq"
)
KRAKEN2_NUCL_UNCLASSIF_FASTQ_R2_FILE = join(
    KRAKEN2_NUCL_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_unclassif_2.fq"
)
KRAKEN2_NUCL_UNCLASSIF_FASTQ_SE_FILE = join(
    KRAKEN2_NUCL_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_unclassif_s.fq"
)
KRAKEN2_NUCL_REPORT_FILE = join(
    KRAKEN2_NUCL_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_report.tsv"
)
KRAKEN2_NUCL_CLASSIFY_LOG = join(
    KRAKEN2_NUCL_CLASSIFY_FILE_LOG_DIR, "{rg_id}_classify.log"
)

KRAKEN2_PROT_CLASSIF_FASTQ_R1_FILE = join(
    KRAKEN2_PROT_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_classif_1.fq"
)
KRAKEN2_PROT_CLASSIF_FASTQ_R2_FILE = join(
    KRAKEN2_PROT_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_classif_2.fq"
)
KRAKEN2_PROT_CLASSIF_FASTQ_SE_FILE = join(
    KRAKEN2_PROT_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_classif_s.fq"
)
KRAKEN2_PROT_UNCLASSIF_FASTQ_R1_FILE = join(
    KRAKEN2_PROT_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_unclassif_1.fq"
)
KRAKEN2_PROT_UNCLASSIF_FASTQ_R2_FILE = join(
    KRAKEN2_PROT_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_unclassif_2.fq"
)
KRAKEN2_PROT_UNCLASSIF_FASTQ_SE_FILE = join(
    KRAKEN2_PROT_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_unclassif_s.fq"
)
KRAKEN2_PROT_REPORT_FILE = join(
    KRAKEN2_PROT_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_report.tsv"
)
KRAKEN2_PROT_CLASSIFY_LOG = join(
    KRAKEN2_PROT_CLASSIFY_FILE_LOG_DIR, "{rg_id}_classify.log"
)


KRAKEN2_COMBINED_REPORT_RESULTS_DIR = join(KRAKEN2_RESULTS_DIR, "combine_reports")
KRAKEN2_COMBINED_REPORT_LOG_DIR = join(KRAKEN2_LOG_DIR, "combine_reports")
KRAKEN2_COMBINED_REPORT_FILE_RESULTS_DIR = join(
    KRAKEN2_COMBINED_REPORT_RESULTS_DIR, "{bam_id}"
)
KRAKEN2_COMBINED_REPORT_FILE_LOG_DIR = join(KRAKEN2_COMBINED_REPORT_LOG_DIR, "{bam_id}")
KRAKEN2_COMBINED_REPORT_FILE = join(
    KRAKEN2_COMBINED_REPORT_FILE_RESULTS_DIR, "{rg_id}_report.tsv"
)
KRAKEN2_COMBINED_REPORT_LOG = join(
    KRAKEN2_COMBINED_REPORT_FILE_LOG_DIR, "{rg_id}_report.log"
)

EUPATHDB_RESOURCES_DIR = join(RESOURCES_DIR, "eupathdb")
EUPATHDB_LOG_DIR = join(LOG_DIR, "eupathdb")

EUPATHDB_FASTA_TGZ_URL = join(EUPATHDB_BASE_URL, EUPATHDB_FASTA_TGZ_FILENAME)
EUPATHDB_FASTA_TGZ_FILE = join(EUPATHDB_RESOURCES_DIR, EUPATHDB_FASTA_TGZ_FILENAME)
EUPATHDB_FASTA_TGZ_LOG = join(
    EUPATHDB_LOG_DIR, f"download_{EUPATHDB_FASTA_TGZ_FILENAME}.log"
)
EUPATHDB_FASTA_BASENAME = re.sub(
    r"(\.tar\.gz|\.tgz)$", "", EUPATHDB_FASTA_TGZ_FILENAME, re.IGNORECASE
)
EUPATHDB_FASTA_DIR = join(EUPATHDB_RESOURCES_DIR, EUPATHDB_FASTA_BASENAME)
EUPATHDB_FASTA_LOG = join(EUPATHDB_LOG_DIR, f"untar_{EUPATHDB_FASTA_TGZ_FILENAME}.log")

EUPATHDB_MERGED_FASTA_FILE = join(
    EUPATHDB_RESOURCES_DIR, f"{EUPATHDB_FASTA_BASENAME}.fna"
)
EUPATHDB_MERGED_FASTA_LOG = join(EUPATHDB_LOG_DIR, f"{EUPATHDB_FASTA_BASENAME}_fna.log")

KRAKEN2_EUPATHDB_LIB_DIR = join(KRAKEN2_NUCL_DB_DIR, "library", "eupathdb")
KRAKEN2_EUPATHDB_LIB_FASTA_FILE = join(KRAKEN2_EUPATHDB_LIB_DIR, "library.fna")
KRAKEN2_EUPATHDB_LIB_FASTA_LOG = join(EUPATHDB_LOG_DIR, "library_fna.log")

EUPATHDB_SEQID2TAXID_MAP_URL = join(
    EUPATHDB_BASE_URL, EUPATHDB_SEQID2TAXID_MAP_FILENAME
)
EUPATHDB_SEQID2TAXID_MAP_FILE = join(
    EUPATHDB_RESOURCES_DIR, EUPATHDB_SEQID2TAXID_MAP_FILENAME
)
EUPATHDB_SEQID2TAXID_MAP_LOG = join(
    EUPATHDB_LOG_DIR, f"download_{EUPATHDB_SEQID2TAXID_MAP_FILENAME}.log"
)
KRAKEN2_EUPATHDB_LIB_IDMAP_FILE = join(KRAKEN2_EUPATHDB_LIB_DIR, "prelim_map.txt")
KRAKEN2_EUPATHDB_LIB_IDMAP_LOG = join(EUPATHDB_LOG_DIR, "prelim_map.log")

KRAKENUNIQ_RESULTS_DIR = join(RESULTS_DIR, "krakenuniq")
KRAKENUNIQ_LOG_DIR = join(LOG_DIR, "krakenuniq")
KRAKENUNIQ_DB_DIR = join(KRAKEN_DB_BASEDIR, KRAKEN_DB_NAME)
KRAKENUNIQ_DB_LOG_DIR = join(KRAKENUNIQ_LOG_DIR, "db", KRAKEN_DB_NAME)
KRAKENUNIQ_DB_TAX_DIR = join(KRAKENUNIQ_DB_DIR, "taxonomy")
KRAKENUNIQ_DB_TAX_LOG = join(KRAKENUNIQ_DB_LOG_DIR, "download_taxonomy.log")
KRAKENUNIQ_DB_LIB_DIR = join(KRAKENUNIQ_DB_DIR, "library", "{kulib}")
KRAKENUNIQ_DB_LIB_LOG = join(KRAKENUNIQ_DB_LOG_DIR, "download_{kulib}.log")
KRAKENUNIQ_DB_TAX_DONE_FILE = join(KRAKENUNIQ_DB_TAX_DIR, "download_taxonomy.done")
KRAKENUNIQ_DB_LIB_DONE_FILE = join(KRAKENUNIQ_DB_LIB_DIR, "download_{kulib}.done")

KRAKENUNIQ_DB_LOG = join(KRAKENUNIQ_DB_LOG_DIR, "krakenuniq_db.log")
KRAKENUNIQ_DB_DONE_FILE = join(KRAKENUNIQ_DB_DIR, "krakenuniq_db.done")

KRAKENUNIQ_CLASSIFY_RESULTS_DIR = join(
    KRAKENUNIQ_RESULTS_DIR, "classify", KRAKEN_DB_NAME
)
KRAKENUNIQ_CLASSIFY_LOG_DIR = join(KRAKENUNIQ_LOG_DIR, "classify", KRAKEN_DB_NAME)
KRAKENUNIQ_CLASSIFY_FILE_RESULTS_DIR = join(KRAKENUNIQ_CLASSIFY_RESULTS_DIR, "{bam_id}")
KRAKENUNIQ_CLASSIFY_FILE_LOG_DIR = join(KRAKENUNIQ_CLASSIFY_LOG_DIR, "{bam_id}")

KRAKENUNIQ_CLASSIF_FASTQ_R1_FILE = join(
    KRAKENUNIQ_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_classif_1.fq.gz"
)
KRAKENUNIQ_CLASSIF_FASTQ_R2_FILE = join(
    KRAKENUNIQ_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_classif_2.fq.gz"
)
KRAKENUNIQ_CLASSIF_FASTQ_SE_FILE = join(
    KRAKENUNIQ_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_classif_s.fq.gz"
)
KRAKENUNIQ_UNCLASSIF_FASTQ_R1_FILE = join(
    KRAKENUNIQ_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_unclassif_1.fq.gz"
)
KRAKENUNIQ_UNCLASSIF_FASTQ_R2_FILE = join(
    KRAKENUNIQ_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_unclassif_2.fq.gz"
)
KRAKENUNIQ_UNCLASSIF_FASTQ_SE_FILE = join(
    KRAKENUNIQ_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_unclassif_s.fq.gz"
)
KRAKENUNIQ_REPORT_FILE = join(
    KRAKENUNIQ_CLASSIFY_FILE_RESULTS_DIR, "{rg_id}_report.tsv"
)
KRAKENUNIQ_CLASSIFY_LOG = join(KRAKENUNIQ_CLASSIFY_FILE_LOG_DIR, "{rg_id}_classify.log")

READ_LENGTH_RESULTS_DIR = join(RESULTS_DIR, "read_length")
READ_LENGTH_LOG_DIR = join(LOG_DIR, "read_length")
READ_LENGTH_FILE_RESULTS_DIR = join(READ_LENGTH_RESULTS_DIR, "{bam_id}")
READ_LENGTH_FILE_LOG_DIR = join(READ_LENGTH_LOG_DIR, "{bam_id}")

READ_LENGTH_HISTOGRAM_FILE = join(READ_LENGTH_FILE_RESULTS_DIR, "{rg_id}_histogram.tsv")
READ_LENGTH_FILE = join(READ_LENGTH_FILE_RESULTS_DIR, "{rg_id}_length.txt")
READ_LENGTH_HISTOGRAM_LOG = join(READ_LENGTH_FILE_LOG_DIR, "{rg_id}_histogram.log")
READ_LENGTH_LOG = join(READ_LENGTH_FILE_LOG_DIR, "{rg_id}_length.log")

BRACKEN_RESULTS_DIR = join(RESULTS_DIR, "bracken")
BRACKEN_LOG_DIR = join(LOG_DIR, "bracken")
BRACKEN_DB_LOG_DIR = join(BRACKEN_LOG_DIR, "db")
BRACKEN_QUANT_RESULTS_DIR = join(BRACKEN_RESULTS_DIR, "quant")
BRACKEN_QUANT_LOG_DIR = join(BRACKEN_LOG_DIR, "quant")

BRACKEN_DB_LOG = join(BRACKEN_DB_LOG_DIR, "bracken_db_{readlen}.log")
BRACKEN_DB_DONE_FILE = join(
    KRAKEN2_NUCL_DB_DIR if KRAKEN_MODE == "kraken2" else KRAKENUNIQ_DB_DIR,
    "bracken_db_{readlen}.done",
)
BRACKEN_QUANT_FILE_RESULTS_DIR = join(BRACKEN_QUANT_RESULTS_DIR, "{bam_id}")
BRACKEN_QUANT_FILE_LOG_DIR = join(BRACKEN_QUANT_LOG_DIR, "{bam_id}")
BRACKEN_COUNT_FILE = join(BRACKEN_QUANT_FILE_RESULTS_DIR, "{rg_id}_counts.tsv")
BRACKEN_REPORT_FILE = join(BRACKEN_QUANT_FILE_RESULTS_DIR, "{rg_id}_report.tsv")
BRACKEN_QUANT_LOG = join(BRACKEN_QUANT_FILE_LOG_DIR, "{rg_id}_quant.log")

BRACKEN_COMBINED_RESULTS_DIR = join(BRACKEN_RESULTS_DIR, "combined_counts")
BRACKEN_COMBINED_LOG_DIR = join(BRACKEN_LOG_DIR, "combined_counts")
BRACKEN_COMBINED_COUNT_FILE = join(BRACKEN_COMBINED_RESULTS_DIR, "{bam_id}_counts.tsv")
BRACKEN_COMBINED_COUNT_LOG = join(BRACKEN_COMBINED_LOG_DIR, "{bam_id}_counts.log")

BRACKEN_COUNT_MATRIX_RESULTS_DIR = join(BRACKEN_RESULTS_DIR, "matrix")
BRACKEN_COUNT_MATRIX_LOG_DIR = join(BRACKEN_LOG_DIR, "matrix")
BRACKEN_COUNT_MATRIX_FILE = join(
    BRACKEN_COUNT_MATRIX_RESULTS_DIR, f"{STUDY_NAME}_count_matrix.tsv"
)
BRACKEN_COUNT_MATRIX_LOG = join(
    BRACKEN_COUNT_MATRIX_LOG_DIR, f"{STUDY_NAME}_count_matrix.log"
)
BRACKEN_BAM_IDS = GDC_BAM_META_DF["file_id"].tolist()

HOST_BUILD_THREADS = (
    workflow.cores
    if config[HOST_FILTER_MODE]["build"]["threads"] == "all"
    else config[HOST_FILTER_MODE]["build"]["threads"]
)
HOST_ALIGN_THREADS = (
    workflow.cores
    if config[HOST_FILTER_MODE]["align"]["threads"] == "all"
    else config[HOST_FILTER_MODE]["align"]["threads"]
)
KRAKEN2_K2_THREADS = (
    workflow.cores
    if config["kraken2"]["k2"]["threads"] == "all"
    else config["kraken2"]["k2"]["threads"]
)
KRAKEN2_BUILD_THREADS = (
    workflow.cores
    if config["kraken2"]["build"]["threads"] == "all"
    else config["kraken2"]["build"]["threads"]
)
KRAKEN2_CLASSIFY_THREADS = (
    workflow.cores
    if config["kraken2"]["classify"]["threads"] == "all"
    else config["kraken2"]["classify"]["threads"]
)
KRAKENUNIQ_DOWNLOAD_THREADS = (
    workflow.cores
    if config["krakenuniq"]["download"]["threads"] == "all"
    else config["krakenuniq"]["download"]["threads"]
)
KRAKENUNIQ_BUILD_THREADS = (
    workflow.cores
    if config["krakenuniq"]["build"]["threads"] == "all"
    else config["krakenuniq"]["build"]["threads"]
)
KRAKENUNIQ_CLASSIFY_THREADS = (
    workflow.cores
    if config["krakenuniq"]["classify"]["threads"] == "all"
    else config["krakenuniq"]["classify"]["threads"]
)
BBMAP_READLENGTH_THREADS = (
    workflow.cores
    if config["bbmap"]["readlength"]["threads"] == "all"
    else config["bbmap"]["readlength"]["threads"]
)
BRACKEN_BUILD_THREADS = (
    workflow.cores
    if config["bracken"]["build"]["threads"] == "all"
    else config["bracken"]["build"]["threads"]
)

BIOBAMBAM2_BAMTOFASTQ_WRAPPER = join(
    LOCAL_WRAPPERS_BASE_URL, "bio/biobambam2/bamtofastq"
)
HOST_BUILD_WRAPPER = join(LOCAL_WRAPPERS_BASE_URL, f"bio/{HOST_FILTER_MODE}/build")
HOST_ALIGN_WRAPPER = join(LOCAL_WRAPPERS_BASE_URL, f"bio/{HOST_FILTER_MODE}/align")
KRAKEN2_K2_WRAPPER = join(LOCAL_WRAPPERS_BASE_URL, "bio/kraken2/k2")
KRAKEN2_BUILD_WRAPPER = join(LOCAL_WRAPPERS_BASE_URL, "bio/kraken2/build")
KRAKEN2_CLASSIFY_WRAPPER = join(LOCAL_WRAPPERS_BASE_URL, "bio/kraken2/classify")
KRAKENTOOLS_COMBINE_KREPORTS_WRAPPER = join(
    LOCAL_WRAPPERS_BASE_URL, "bio/krakentools/combine_kreports"
)
KRAKENUNIQ_DOWNLOAD_WRAPPER = join(LOCAL_WRAPPERS_BASE_URL, "bio/krakenuniq/download")
KRAKENUNIQ_BUILD_WRAPPER = join(LOCAL_WRAPPERS_BASE_URL, "bio/krakenuniq/build")
KRAKENUNIQ_CLASSIFY_WRAPPER = join(LOCAL_WRAPPERS_BASE_URL, "bio/krakenuniq/classify")
BRACKEN_BUILD_WRAPPER = join(LOCAL_WRAPPERS_BASE_URL, "bio/bracken/build")
BRACKEN_QUANT_WRAPPER = join(LOCAL_WRAPPERS_BASE_URL, "bio/bracken/quant")
BBMAP_READLENGTH_WRAPPER = join(LOCAL_WRAPPERS_BASE_URL, "bio/bbmap/readlength")


wildcard_constraints:
    **{
        w: "|".join(set([re.escape(str(v)) for v in l]))
        for w, l in EXPAND_PARAMS.items()
        if w not in ("bam_id", "rg_id")
    },
    bam_id=r"[0-9a-f\-]{36}",
    rg_id=r"[0-9a-f\-]{36}",


include: join(RULES_DIR, "db_build.smk")
include: join(RULES_DIR, "eupathdb.smk")
include: join(RULES_DIR, "gdc_file.smk")
include: join(RULES_DIR, "host_filter.smk")
include: join(RULES_DIR, "read_classif.smk")
include: join(RULES_DIR, "read_length.smk")
include: join(RULES_DIR, "read_quant.smk")


rule all:
    input:
        # expand(GDC_UNMAPPED_BAM_FILE, **EXPAND_PARAMS),
        # expand(GDC_UNMAPPED_FASTQ_DIR, **EXPAND_PARAMS),
        # HOST_REF_FASTA_FILE,
        # HOST_GENOME_INDEX_DIR,
        # expand(KRAKEN2_DB_TAX_DONE_FILE, **EXPAND_PARAMS),
        # expand(KRAKEN2_NUCL_DB_LIB_DONE_FILE, **EXPAND_PARAMS),
        # expand(KRAKEN2_PROT_DB_LIB_DONE_FILE, **EXPAND_PARAMS),
        # EUPATHDB_FASTA_TGZ_FILE,
        # EUPATHDB_FASTA_DIR,
        # EUPATHDB_MERGED_FASTA_FILE,
        # EUPATHDB_SEQID2TAXID_MAP_FILE,
        # KRAKEN2_EUPATHDB_LIB_IDMAP_FILE,
        # KRAKEN2_EUPATHDB_LIB_FASTA_FILE,
        # expand(KRAKEN2_DB_DONE_FILE, **EXPAND_PARAMS),
        # expand(BRACKEN_DB_DONE_FILE, **EXPAND_PARAMS),
        # expand(BRACKEN_COMBINED_COUNT_FILE, **EXPAND_PARAMS),
        BRACKEN_COUNT_MATRIX_FILE,


def clean(*dirs):
    for clean_dir in dirs:
        if exists(clean_dir):
            rmtree(clean_dir)
        for dirpath, dirnames, filenames in sorted(walk(getcwd())):
            for name in dirnames:
                if name == "__pycache__":
                    pycache_dir = join(dirpath, name)
                    if exists(pycache_dir):
                        rmtree(pycache_dir)


rule clean:
    run:
        clean(RESULTS_DIR, LOG_DIR)


rule clean_all:
    run:
        clean(RESOURCES_DIR, RESULTS_DIR, LOG_DIR)
